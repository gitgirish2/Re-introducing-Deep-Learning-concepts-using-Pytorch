{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM2T7DC_HUKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1VxiH5bHXrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2VOnN_rHg6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char = ['c','h','o','p','r','t','y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psy3EfC1Hjhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = [[2,7,14,15,17,19,24]]\n",
        "x_one_hot = [[0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "             [0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "             [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0],\n",
        "             [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0],\n",
        "             [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0],\n",
        "             [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0],\n",
        "             [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0]\n",
        "            ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDaVeCcmHqXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_data = [15,24,19,14,17,2,7]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJPaSuycHrLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Variable(torch.Tensor(x_one_hot))\n",
        "labels = Variable(torch.LongTensor(y_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP9eug6YH06-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 7\n",
        "input_size = 7 \n",
        "hidden_size = 7\n",
        "batch_size = 1 # One Sentence\n",
        "sequence_length = 1 # Let go one by one \n",
        "num_layers = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6neaTL0tH4BF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                          batch_first=True)\n",
        "    \n",
        "    def forward(self, x, hidden, cell):\n",
        "        x = x.view(batch_size, sequence_length, input_size)\n",
        "        out, (hidden, cell) = self.lstm(x, hidden, cell)\n",
        "        out= out.view(-1, num_classes)\n",
        "        return hidden,out, cell\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(num_layers, batch_size, hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQNVvcdSIAjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTMModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PLB1YaQIF6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    loss = 0\n",
        "    hidden = model.init_hidden()\n",
        "    cell = model.init_hidden()\n",
        "    print(\"Predicted String\")\n",
        "    for ins, label in zip(inputs,labels):\n",
        "        hidden, output, cell = model(ins, hidden, cell)\n",
        "        val, idx = output.max(1)\n",
        "        print(char[idx.data[0]])\n",
        "        loss+=criterion(output, label)\n",
        "    \n",
        "    print(\", epoch: %d, loss: %1.3f\" % (epoch+1, loss.data[0]))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}